{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tWAmx7mQYX1b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = tf.convert_to_tensor(x_train, dtype = tf.float32)\n",
        "y_train = tf.convert_to_tensor(y_train, dtype = tf.int32)\n",
        "\n",
        "x_test = tf.convert_to_tensor(x_test, dtype = tf.float32)\n",
        "y_test = tf.convert_to_tensor(y_test, dtype = tf.int32)\n",
        "\n",
        "x_train = x_train/255.0\n",
        "x_train = tf.expand_dims(x_train,axis = -1)\n",
        "\n",
        "x_test = x_test/255.0\n",
        "x_test = tf.expand_dims(x_test,axis = -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dhhwJsFY4_5",
        "outputId": "6c4f133a-9b7a-495a-e0b2-b95db039ec1e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = tf.keras.models.Sequential([\n",
        "\n",
        "  Conv2D(filters = 6, kernel_size = 8, activation = 'relu'),\n",
        "  MaxPooling2D(pool_size =(2,2)),\n",
        "  Conv2D(filters = 15, kernel_size = 4, activation = 'relu'),\n",
        "  MaxPooling2D(pool_size =(2,2)),\n",
        "\n",
        "  Flatten(),\n",
        "\n",
        "  Dense(128, activation = 'relu'),\n",
        "  Dense(10, activation = 'softmax')\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "EdVXHAn3ZsBw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.compile(optimizer = 'adam',\n",
        "                 loss = 'sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "my_model.fit(x_train, y_train, epochs = 3, batch_size = 1024)\n",
        "\n",
        "my_model.evaluate(x_test, y_test, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCCENTSmamwo",
        "outputId": "ab6cd51c-3dc7-476d-9d09-15043eb8514c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "59/59 [==============================] - 21s 325ms/step - loss: 1.2421 - accuracy: 0.6794\n",
            "Epoch 2/3\n",
            "59/59 [==============================] - 21s 352ms/step - loss: 0.3747 - accuracy: 0.8890\n",
            "Epoch 3/3\n",
            "59/59 [==============================] - 20s 336ms/step - loss: 0.2749 - accuracy: 0.9183\n",
            "313/313 - 2s - loss: 0.2295 - accuracy: 0.9322 - 2s/epoch - 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2294807881116867, 0.932200014591217]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1024\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(BATCH_SIZE)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "cpJMTDCVbDRK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "class Linear(Layer):\n",
        "  \"\"\"y = Wx + b\"\"\"\n",
        "\n",
        "  def __init__(self, units = 32):\n",
        "    super(Linear, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.W = self.add_weight(shape = (input_shape[-1],self.units),\n",
        "                             initializer = 'random_normal',trainable = True)\n",
        "    self.b = self.add_weight(shape = (self.units,),\n",
        "                             initializer = 'random_normal', trainable = True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.W) + self.b"
      ],
      "metadata": {
        "id": "LV4wJCO-biOL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleDense(Layer):\n",
        "  \"\"\"Linear-relu + Linear-Softmax\"\"\"\n",
        "\n",
        "  def __init__(self, nb_classes):\n",
        "    super(DoubleDense, self).__init__()\n",
        "    self.nb_classes = nb_classes\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.linear_1 = Linear(units = 128)\n",
        "    self.linear_2 = Linear(units = self.nb_classes)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = tf.nn.relu(self.linear_1(inputs))\n",
        "    x = tf.nn.softmax(self.linear_2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "xYiKDC36cUzo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvPool2D(Layer):\n",
        "  \"\"\"Conv2D-relu + MaxPooling2D\"\"\"\n",
        "\n",
        "  def __init__(self, nb_kernels, kernel_size):\n",
        "    super(ConvPool2D, self).__init__()\n",
        "    self.nb_kernels = nb_kernels\n",
        "    self.kernel_size = kernel_size\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.conv_2D = Conv2D(filters = self.nb_kernels,\n",
        "                          kernel_size = self.kernel_size,\n",
        "                          activation = 'relu')\n",
        "    self.pool_2D = MaxPooling2D(pool_size = (2,2))\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.conv_2D(inputs)\n",
        "    x = self.pool_2D(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "blbEZcNxdGgQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "\n",
        "class MyModel(Model):\n",
        "  def __init__(self, nb_classes):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.nb_classes = nb_classes\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.conv_pool_1 = ConvPool2D(nb_kernels = 6, kernel_size = 8)\n",
        "    self.conv_pool_2 = ConvPool2D(nb_kernels = 15, kernel_size = 4)\n",
        "    self.flatten = Flatten()\n",
        "    self.double_dense = DoubleDense(nb_classes = self.nb_classes)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    self.x_0 = self.conv_pool_1(inputs)\n",
        "    self.x_1 = self.conv_pool_2(self.x_0)\n",
        "    self.x_2 = self.flatten(self.x_1)\n",
        "    self.predictions = self.double_dense(self.x_2)\n",
        "    return self.predictions"
      ],
      "metadata": {
        "id": "zB2frm3KeTZX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.legacy.Adam()\n",
        "\n",
        "my_model = MyModel(nb_classes = 10)\n",
        "my_model.compile(optimizer, loss_function)"
      ],
      "metadata": {
        "id": "0c0Di2jWfbh-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.legacy.Adam()\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
        "train_accuracy =tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
        "test_accuracy =tf.keras.metrics.SparseCategoricalAccuracy(name = 'test_accuracy')"
      ],
      "metadata": {
        "id": "hH6wOEHvfw3-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x= tf.Variable(3.0)\n",
        "with tf.GradientTape() as tape:\n",
        "  y = tf.square(x)\n",
        "dy_dx = tape.gradient(y,x)\n",
        "print(dy_dx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNs9nbP5gNOH",
        "outputId": "4d021add-229e-4be8-b8bc-4e2eca62c439"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(6.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(images,labels):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    predictions = my_model(images)\n",
        "    loss = loss_function(labels, predictions)\n",
        "    gradients = tape.gradient(loss, my_model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients,my_model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "def test_step(images, labels):\n",
        "  predictions = my_model(images)\n",
        "  t_loss = loss_function(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "metadata": {
        "id": "9Sy6s2g2ghoH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "my_model = MyModel(nb_classes = 10)\n",
        "start = time.time()\n",
        "\n",
        "for epoch in range(3):\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  template = 'Epoch{:0f}, Loss:{:.3f}, Accuracy:{:.3f}' + 'Test Loss:{:.3f}, Test Accuracy:{:.3f}'\n",
        "  print(template.format(epoch + 1,train_loss.result(), train_accuracy.result()*100,\n",
        "                        test_loss.result(), test_accuracy.result()*100))\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "end = time.time()\n",
        "print('Time = ', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf-lGAFihWP2",
        "outputId": "cc064cf6-61f2-4b58-80a7-c047937a2fa8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch1.000000, Loss:1.387, Accuracy:66.175Test Loss:0.471, Test Accuracy:85.900\n",
            "Epoch2.000000, Loss:0.403, Accuracy:87.932Test Loss:0.301, Test Accuracy:91.100\n",
            "Epoch3.000000, Loss:0.287, Accuracy:91.563Test Loss:0.228, Test Accuracy:93.330\n",
            "Time =  126.71333193778992\n"
          ]
        }
      ]
    }
  ]
}